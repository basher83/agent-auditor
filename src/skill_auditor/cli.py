#!/usr/bin/env -S uv run --script --quiet
# /// script
# requires-python = ">=3.11"
# dependencies = [
#     "claude-agent-sdk>=0.1.8",
# ]
# ///
"""
Skill Auditor - Claude Agent SDK Application

Deterministic skill auditing with Python extraction and Claude analysis.

Usage:
    python -m skill_auditor.cli /path/to/skill/directory
"""

import json
import sys
from pathlib import Path

import anyio
from claude_agent_sdk import AssistantMessage, ClaudeAgentOptions, ResultMessage, TextBlock, query

# Import metrics extractor
from .metrics_extractor import extract_skill_metrics
from .validation import validate_metrics_structure

# Audit thresholds
MAX_SKILL_LINE_COUNT = 500  # Official Claude Code skill specification (soft recommendation)


def validate_and_format_deterministic(metrics: dict) -> tuple[str, bool]:
    """
    Validate metrics and format deterministic output.

    Args:
        metrics: Extracted skill metrics

    Returns:
        Tuple of (formatted_output, has_blockers)
    """
    blockers = []
    warnings = []

    # B1: No forbidden files
    if metrics["forbidden_files"]:
        blockers.append(f"B1: Forbidden files detected: {', '.join(metrics['forbidden_files'])}")

    # B2: Valid YAML frontmatter
    if not (metrics["yaml_delimiters"] == 2 and metrics["has_name"] and metrics["has_description"]):
        issues = []
        if metrics["yaml_delimiters"] != 2:
            issues.append(f"expected 2 yaml delimiters, found {metrics['yaml_delimiters']}")
        if not metrics["has_name"]:
            issues.append("missing 'name' field")
        if not metrics["has_description"]:
            issues.append("missing 'description' field")
        blockers.append(f"B2: Invalid YAML frontmatter ({', '.join(issues)})")

    # W1: Line count under 500 (soft recommendation, not blocker)
    if metrics["line_count"] >= MAX_SKILL_LINE_COUNT:
        warnings.append(
            f"W1: SKILL.md is long ({metrics['line_count']} lines, recommended max {MAX_SKILL_LINE_COUNT})"
        )

    # NOTE: W1 (quoted phrases) and W3 (domain indicators) removed
    # These were not actual requirements per official Anthropic documentation
    # Tested against 69 real skills including official Anthropic examples
    # 78% and 88% false positive rates respectively

    # NOTE: B4 (implementation details) removed
    # Official Anthropic skills include implementation details in descriptions
    # The requirement is "be specific" not "avoid details"

    # Format output
    output_lines = []

    # Status line
    if blockers:
        output_lines.append("\nðŸ”´ BLOCKED")
    elif warnings:
        output_lines.append("\nðŸŸ¡ READY WITH WARNINGS")
    else:
        output_lines.append("\nðŸŸ¢ READY")

    # Blockers section
    if blockers:
        output_lines.append("\nâŒ BLOCKERS:")
        for b in blockers:
            output_lines.append(f"  {b}")

    # Warnings section
    if warnings:
        output_lines.append("\nâš ï¸  WARNINGS:")
        for w in warnings:
            output_lines.append(f"  {w}")

    # Next steps
    if blockers or warnings:
        output_lines.append("\nðŸ’¡ TIP: Run with --explain for detailed fix suggestions")

    return "\n".join(output_lines), bool(blockers)


async def audit_skill(skill_path: Path, use_claude: bool = False):
    """
    Audit a skill using deterministic Python extraction + optional Claude analysis.

    Args:
        skill_path: Path to skill directory
        use_claude: If True, use Claude for detailed explanations. If False, show deterministic results only.
    """
    print(f"ðŸ” Auditing skill: {skill_path}")
    print("=" * 60)

    # Step 1: Extract metrics deterministically (Python, no bash)
    print("\nðŸ“Š Extracting metrics...")
    try:
        metrics = extract_skill_metrics(skill_path)
    except FileNotFoundError as e:
        print(f"âŒ Error: {e}")
        print(f"   Please ensure SKILL.md exists in {skill_path}")
        return
    except PermissionError as e:
        print(f"âŒ Permission Error: {e}")
        print("   Please check file permissions and try again.")
        return
    except ValueError as e:
        # This catches UnicodeDecodeError wrapped as ValueError
        print(f"âŒ Encoding Error: {e}")
        print("   Please ensure SKILL.md is properly UTF-8 encoded.")
        return
    except OSError as e:
        print(f"âŒ I/O Error: {e}")
        print("   Please check that all files are accessible.")
        return
    except Exception as e:
        print(f"âŒ Unexpected Error during metrics extraction: {type(e).__name__}: {e}")
        print("   This may be a bug. Please report it with the error details above.")
        return

    # Validate metrics structure before proceeding

    try:
        validate_metrics_structure(metrics)
    except ValueError as e:
        print(f"âŒ Internal Error: {e}")
        return

    print(f"âœ… Extracted {len(metrics)} metrics")
    print(f"   - Line count: {metrics['line_count']}")
    print(f"   - YAML delimiters: {metrics['yaml_delimiters']}")
    print(f"   - Forbidden files: {len(metrics['forbidden_files'])}")

    # Step 2: Validate and output results
    if not use_claude:
        # Fast mode: Deterministic output only
        print("\nðŸ“Š Running deterministic validation...")
        output, has_blockers = validate_and_format_deterministic(metrics)
        print(output)
        return

    # Step 3: Claude-enhanced mode (--explain flag)
    print("\nðŸ¤– Using Claude for detailed analysis...")

    # Step 4: Configure SDK with NO tools (analysis only)
    options = ClaudeAgentOptions(
        allowed_tools=[],  # NO TOOLS - prevents hallucination
        model="claude-sonnet-4-5",
        max_turns=1,  # Single analysis, no conversation
    )

    # Step 3: Build analysis prompt with metrics
    prompt = build_analysis_prompt(metrics)

    # Step 4: Query Claude for analysis
    print("\nðŸ¤– Analyzing metrics with Claude...")

    try:
        async for message in query(prompt=prompt, options=options):
            if isinstance(message, AssistantMessage):
                for block in message.content:
                    if isinstance(block, TextBlock):
                        print(block.text)

            elif isinstance(message, ResultMessage):
                if message.total_cost_usd:
                    print(f"\nðŸ’° Cost: ${message.total_cost_usd:.4f}")
                if message.duration_ms:
                    print(f"â±ï¸  Duration: {message.duration_ms}ms")

    except Exception as e:
        error_type = type(e).__name__
        error_msg = str(e)

        print(f"\nâŒ Claude API Error: {error_type}")
        print(f"   {error_msg}")

        # Provide actionable guidance based on error type
        error_lower = (error_type + " " + error_msg).lower()
        if (
            "authentication" in error_lower
            or "auth" in error_lower
            or "api key" in error_lower
            or "invalid" in error_lower
        ):
            print("\n   ðŸ’¡ Please check your ANTHROPIC_API_KEY environment variable.")
            print("      Set it with: export ANTHROPIC_API_KEY=your-key-here")
        elif "connection" in error_lower or "network" in error_lower:
            print("\n   ðŸ’¡ Please check your internet connection and try again.")
        elif "rate" in error_lower or "limit" in error_lower:
            print("\n   ðŸ’¡ Rate limit exceeded. Please wait a moment and try again.")
        else:
            print("\n   ðŸ’¡ This may be a temporary service issue. Please try again later.")
            print("      If the problem persists, check https://status.anthropic.com")

        return


def build_analysis_prompt(metrics: dict) -> str:
    """
    Build the analysis prompt with extracted metrics.

    Args:
        metrics: Extracted skill metrics

    Returns:
        Formatted prompt for Claude
    """
    # Calculate binary check results
    b1_pass = len(metrics["forbidden_files"]) == 0
    b2_pass = metrics["yaml_delimiters"] == 2 and metrics["has_name"] and metrics["has_description"]
    w1_pass = metrics["line_count"] < MAX_SKILL_LINE_COUNT

    prompt = f"""Audit the following skill metrics:

## Extracted Metrics

```json
{json.dumps(metrics, indent=2)}
```

## Binary Check Results

**BLOCKERS (Official Requirements from Anthropic Documentation):**
- B1: No forbidden files (README.md, INSTALL.md) â†’ {"âœ… PASS" if b1_pass else "âŒ FAIL"}
- B2: Valid YAML frontmatter with name + description â†’ {"âœ… PASS" if b2_pass else "âŒ FAIL"}

**WARNINGS (Soft Recommendations):**
- W1: SKILL.md under 500 lines â†’ {"âœ… PASS" if w1_pass else "âŒ FAIL"}

## Your Task

Generate a skill audit report following this format:

# Skill Audit Report: {metrics["skill_name"]}

**Status:** [ðŸ”´ BLOCKED | ðŸŸ¡ READY WITH WARNINGS | ðŸŸ¢ READY]

**Breakdown:**
- Blockers: [X] âŒ
- Warnings: [X] âš ï¸

## BLOCKERS âŒ ([X])

[List failed blocker checks with specific evidence from metrics]

## WARNINGS âš ï¸ ([X])

[List failed warning checks with specific evidence from metrics]

## Next Steps

[Specific, actionable fixes based on failed checks]

---

IMPORTANT: Base your analysis ONLY on the metrics provided above. Do not re-extract or assume additional data.
"""

    return prompt


async def main():
    """Main entry point."""
    import argparse

    parser = argparse.ArgumentParser(
        description="Audit Claude Code skills for compliance and effectiveness"
    )
    parser.add_argument("skill_path", type=Path, help="Path to skill directory containing SKILL.md")
    parser.add_argument(
        "--explain",
        action="store_true",
        help="Use Claude to provide detailed explanations and fix suggestions (costs ~$0.004)",
    )

    args = parser.parse_args()
    skill_path = args.skill_path
    use_claude = args.explain

    # Resolve to absolute path
    try:
        skill_path = skill_path.resolve()
    except (OSError, RuntimeError) as e:
        print(f"âŒ Error: Unable to resolve path {skill_path}: {e}")
        print("   Please ensure the path is valid and you have permission to access it.")
        sys.exit(1)

    if not skill_path.exists():
        print(f"âŒ Error: Path does not exist: {skill_path}")
        print("   Please provide a valid path to a skill directory.")
        print("   Example: python -m skill_auditor.cli /path/to/skill/directory")
        sys.exit(1)

    if not skill_path.is_dir():
        print(f"âŒ Error: Path is not a directory: {skill_path}")
        print("   Please provide a path to a skill directory (not a file).")
        sys.exit(1)

    # Check if we can read the directory
    try:
        list(skill_path.iterdir())
    except PermissionError:
        print(f"âŒ Permission Error: Cannot read directory {skill_path}")
        print("   Please check directory permissions and try again.")
        sys.exit(1)

    await audit_skill(skill_path, use_claude=use_claude)


def _main():
    """Synchronous wrapper for console script entry point."""
    anyio.run(main)


if __name__ == "__main__":
    _main()
